### 缓存雪崩
#### 什么是缓存雪崩？
缓存同⼀时间⼤⾯积的失效，所以，后⾯的请求都会落到数据库上，造成数据库短时间内承受⼤
量请求⽽崩掉。

#### 解决方案
- 方案一：设置大部分key的过期时间不一样，比如在原来基础上增加设置1-5s随机值，防止大部分key集体过期，造成缓存雪崩。
- 方案二：
    - 事前：尽量保证整个 redis 集群的⾼可⽤性，发现机器宕机尽快补上。选择合适的内存淘汰策略。
    - 事中：hystrix限流&降级，避免MySQL崩掉
    - 事后：利⽤ redis 持久化机制保存的数据尽快恢复缓存

### 缓存穿透
#### 什么是缓存穿透？
缓存穿透说简单点就是⼤量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这⼀层。举个例⼦：某个⿊客故意制造我们缓存中不存在的 key 发起⼤量请求，导致⼤量请求落到数据库。

#### 解决方案
最基本的就是⾸先做好参数校验，⼀些不合法的参数请求直接抛出异常信息返回给客户端。⽐如查询的数据库 id 不能⼩于 0、传⼊的邮箱格式不对的时候直接返回错误消息给客户端等等。
- 方案一：缓存⽆效 key。 如果缓存和数据库都查不到某个 key 的数据就写⼀个到 redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种⽅式可以解决请求的 key 变化不频繁的情况，如果⿊客恶意攻击，每次构建不同的请求key，会导致 redis 中缓存⼤量⽆效的 key 。很明显，这种⽅案并不能从根本上解决此问题。如果⾮要⽤这种⽅式来解决穿透问题的话，尽量将⽆效的 key的过期时间设置短⼀点⽐如 1 分钟。

- 方案二：布隆过滤器。布隆过滤器是⼀个⾮常神奇的数据结构，通过它我们可以⾮常⽅便地判断⼀个给定数据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“⼈”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当⽤户请求过来，我会先判断⽤户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会⾛下⾯的流程。

### Redis并发竞争key
#### 原因
当多个redis的client同时set key或是多个go协程访问时引起的并发问题。

#### 解决方案
- go mutex锁
- redis `setnx`命令
```go
var ctx = context.Background()

func incr() {
	client := redis.NewClient(&redis.Options{
		Addr:     "localhost:6379",
		Password: "", // no password set
		DB:       0,  // use default DB
	})

	var lockKey = "counter_lock"
	var counterKey = "counter"

	// lock
	resp := client.SetNX(ctx, lockKey, 1, time.Second*5)
	lockSuccess, err := resp.Result()

	if err != nil || !lockSuccess {
		fmt.Println(err, "lock result: ", lockSuccess)
		return
	}

	// counter ++
	getResp := client.Get(ctx, counterKey)
	cntValue, err := getResp.Int64()
	if err == nil || err == redis.Nil {
		cntValue++
		resp := client.Set(ctx, counterKey, cntValue, 0)
		_, err := resp.Result()
		if err != nil {
			// log err
			println("set value error!")
		}
	}
	println("current counter is ", cntValue)

	delResp := client.Del(ctx, lockKey)
	unlockSuccess, err := delResp.Result()
	if err == nil && unlockSuccess > 0 {
		println("unlock success!")
	} else {
		println("unlock failed", err)
	}
}

func main() {
	var wg sync.WaitGroup
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			incr()
		}()
	}
	wg.Wait()
}
```

```shell
<nil> lock result:  false
<nil> lock result:  false
<nil> lock result:  false
<nil> lock result:  false
<nil> lock result:  false
<nil> lock result:  false
current counter is  1
unlock success!

Process finished with exit code 0
```
- 分布式锁（通过一致性协议保证数据可靠性的锁方案）
	- redlock
    - zookeeper
    - etcd


### 如何保证缓存和数据库数据一致性？

#### 先写DB还是先写缓存？
- 先写DB再缓存

1. 单个DB时：
将数据库写和reids写放在一个事务里。
先执行数据库写操作，写操作执行成功后，执行删除缓存key的操作。在下次读取数据的时候，会检测到cache key miss，会自动将数据库中的最新数据更新到缓存里。保证单机读写一致性。
```go
begin tx
    dbSuccess := db.write()
    if dbSuccess {
        cacheSuccess := cache.delete(key)
        if cacheSuccess {
            return ture
        }
        rollback tx
    }
    rollback tx
end tx
```

2. DB集群时：
DB集群时，在读取数据时，程序可能从库读取数据，此时读取的数据可能是旧数据（主数据库还未将新写入的数据同步到从库中），导致读取和写入的数据不一致。
- 解决方案1：订阅从库的binlog日志，当从库数据同步更新后，主动delete cache key或者set cache key。如此，虽说也没有100%解决短暂的数据不一致问题，但是已经将脏数据所存在的时长降到了最低（最终由主从同步的耗时决定）。

- 解决方案2：主数据写入数据库并删除了缓存中的key后，再在缓存中写入一条{ key = dbname + tablename + id，value = null，expire = 3s }数据，当「读数据」的时候发生cache key miss，先判断是否存在这个临时数据，只要在3秒内就会强制走「主库」取数据。保证数据从主数据库读取的最新数据，这里的3s应该是大于主从数据库同步时间的，不然还是会走到方案1的主从数据未同步的问题。
```go
begin tx
    dbSuccess := db.write()
    if dbSuccess {
        cacheSuccess := cache.delete(key)
        if cacheSuccess {
            return ture
        }
        rollback tx
    }
    rollback tx
end tx

key := dbname + tablename + id
// 设置这样一条缓存数据：{ key = dbname + tablename + id，value = null，expire = 3s }
cache.set(key)
```