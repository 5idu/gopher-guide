## 消费者组

### 什么是消费者组

消费者组是Kafka提供的可扩展且具有容错性的消费者机制。消费者组可由多个消费者组成，它们共享一个ID，这个ID叫做Group ID。组内的所有消费者协调在一起来消费订阅主题的所有分区，但是每一个分区只能由同一个消费者组里的一个消费者来消费。理解消费者组记住以下三个特性就好了：

- 消费者组可以有一个或多个消费者实例组成。消费者实例可以是一个进程，也可以是一个进程下的多个线程，一般使用进程更为常见
- Group ID 是一个字符串。以一个Kafka集群中唯一标识一个消费者组

- 消费者组订阅的的主题下的单个分区，只能被同一个消费者组里的单个消费者实例所消费，这个分区当然也可以被其他消费者组消费

### 如何使用消费者组实现消息引擎模型

使用消费者组的特性可以实现消息引起的2大消息模型：**消息队列模型**、**订阅发布模型**

实现消息队列模型：

- 如果所有主题都属于一个消费者组，那么实现的是消息队列模型

实现订阅发布模型：

- 如果所有主题属于不同的消费者组，那么实现的是订阅发布模型

### 如何确定消费者组中消费者实例的数量

理想情况下消费者组的消费者实例等于该Group订阅的主题分区总数。当然也可以小于分区总数或大于分区总数。

举个简单的例子，假设一个 Consumer Group 订阅了 3 个主题，分别是 A、B、C，它们的分区数依次是 1、2、3，那么通常情况下，为该 Group 设置 6 个 Consumer 实例是比较理想的情形，因为它能最大限度地实现高伸缩性。

你可能会问，我能设置小于或大于 6 的实例吗？当然可以！如果你有 3 个实例，那么平均下来每个实例大约消费 2 个分区（6 / 3 = 2）；如果你设置了 8 个实例，那么很遗憾，有 2 个实例（8 – 6 = 2）将不会被分配任何分区，它们永远处于空闲状态。因此，在实际使用过程中一般不推荐设置大于总分区数的 Consumer 实例。设置多余的实例只会浪费资源，而没有任何好处。

### 消费者组的分区策略

- Range分区策略
- RoundRobin轮询分区策略
- Sticky分区策略（最优）

### 消费者组的重平衡机制

**rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区**。

何时触发消费者组重平衡：

- 消费组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。
- 订阅主题数发生变更。Consumer Group 可以使用正则表达式的方式订阅主题，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生 Rebalance。
- 订阅主题的分区数发生变更。Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance

**Rebalance的缺点**

- 重平衡的时候，消费者组里的消费者会停止消费消息
- 重平衡时，消费者组里的所有消费者都会共同参与，全部重新分配所有分区。会出现消费者上的分区重新分配的情况，造成资源浪费。
- 当消费者组里的消费者实例过多时，重平衡时会相当耗时。

### 消费者实例的消费位移管理

老版本消费者实例的消费位移是保存在zookeeper中，但是zookeeper并不适合进行频繁的写更新，而Consumer Group的位移更新却是一个非常频繁的操作。这种大吞吐量的写操作会极大的拖慢zookeeper集群的性能。

新版本的消费位移保存在**__consumer_offsets**这个内部主题中，可以简单的理解为以键值对的形式表示。key保存了三个部分的内容：**<Group ID，主题名，分区号 >**，value保存了位移值，位移提交时的元数据（比如时间戳和用户自定义的数据）等。

通常来说，**当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建_consumer_offsets主题**，当然你也可以手动创建，但是尽量不要这么做，而是让Kafka自动帮你管理_consumer_offsets。

### 消费者提交位移的2种机制

- 自动提交消费位移

  Consumer 端有个参数叫 enable.auto.commit，如果值是 true，则 Consumer 在后台默默地为你定期提交位移，提交间隔由一个专属的参数 auto.commit.interval.ms 来控制。

- 手动提交消费位移

  设置 enable.auto.commit = false时，作为 Consumer 应用开发的你就要承担起位移提交的责任。Kafka Consumer API 为你提供了位移提交的方法，如 consumer.commitSync 等。当调用这些方法时，Kafka 会向位移主题写入相应的消息。

### 消费者组的协调者Coordinator

Coordinator专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。

具体来讲，Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。

所有 Broker 在启动时，都会创建和开启相应的 Coordinator 组件。也就是说，**所有 Broker 都有各自的 Coordinator 组件**。

### 如何确定Coordinator所在的broker

Consumer Group 如何确定为它服务的 Coordinator 在哪台 Broker 上呢？答案就在我们之前说过的 Kafka 内部位移主题 __consumer_offsets 身上。

目前，Kafka 为某个 Consumer Group 确定 Coordinator 所在的 Broker 的算法有 2 个步骤。

第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)。

第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。

简单解释一下上面的算法。首先，Kafka 会计算该 Group 的 group.id 参数的哈希值。比如你有个 Group 的 group.id 设置成了“test-group”，那么它的 hashCode 值就应该是 627841412。其次，Kafka 会计算 __consumer_offsets 的分区数，通常是 50 个分区，之后将刚才那个哈希值对分区数进行取模加求绝对值计算，即 abs(627841412 % 50) = 12。此时，我们就知道了位移主题的分区 12 负责保存这个 Group 的数据。有了分区号，算法的第 2 步就变得很简单了，我们只需要找出位移主题分区 12 的 Leader 副本在哪个 Broker 上就可以了。这个 Broker，就是我们要找的 Coordinator。
